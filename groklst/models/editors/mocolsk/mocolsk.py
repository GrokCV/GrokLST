import torch.nn as nn
import torch
from .dynamic_mlp import *
import torch.nn.functional as F


class MoCoLSK(nn.Module):
    """
    The MoCoLSK only consists of:
    1) the Large Selective Kernel (LSK) pathway;
    2) and the Modality-Conditioned Weight Generation (MCWG) pathway."""

    def __init__(
        self,
        dim: int,
        planes: int,
        hidden: int = 32,
        num_layers: int = 1,
        mlp_type: str = "a",
        kernel_size: int = 3,
    ):
        """
        MoCoLSK.__init__
        Args:
            dim (int): dimension of the HR LST / HR Guidance data.
            planes (int): output dimension of the Dynamic MLP module.
            hidden (int, optional): hidden dimension of the Dynamic MLP module. Defaults to 32.
            num_layers (int, optional): num_layers of the Dynamic MLP module. Defaults to 1.
            mlp_type (str, optional): mlp_type of the Dynamic MLP module. Defaults to "a".
            kernel_size (int, optional): kernel_size of dynamic weight generated by the Modality-Conditioned Weight Generation (MCWG) pathway. Defaults to 3.
        """
        super().__init__()
        self.kernel_size = kernel_size
        self.pool_sizes = [1, 2, 3, 6]
        self.conv_lst = nn.Conv2d(dim, dim, 5, padding=2, groups=dim)
        self.conv_spatial0 = nn.Conv2d(
            dim, dim, 7, stride=1, padding=9, groups=dim, dilation=3
        )

        self.conv1 = nn.Conv2d(dim, dim // 2, 1)
        self.conv2 = nn.Conv2d(dim, dim // 2, 1)
        self.dynamic_mlp = FusionModule(
            inplanes=dim,
            planes=planes,
            hidden=hidden,
            num_layers=num_layers,
            mlp_type=mlp_type,
            kernel_size=kernel_size,
        )
        self.conv = nn.Conv2d(dim // 2, dim, 1)

    def forward(self, lst, gui):
        B, C, H, W = lst.shape
        attn1 = self.conv_lst(lst)
        attn2 = self.conv_spatial0(attn1)

        attn1 = self.conv1(attn1)
        attn2 = self.conv2(attn2)

        attn = torch.cat([attn1, attn2], dim=1)
        avg_attn = torch.mean(attn, dim=1, keepdim=True)
        max_attn, _ = torch.max(attn, dim=1, keepdim=True)
        agg = torch.cat([avg_attn, max_attn], dim=1)

        # PPM
        lst_pools = []
        gui_pools = []
        for pool_size in self.pool_sizes:
            pool = F.adaptive_avg_pool2d(lst, (pool_size, pool_size))
            lst_pools.append(pool.view(B, C, -1))
            pool = F.adaptive_avg_pool2d(gui, (pool_size, pool_size))
            gui_pools.append(pool.view(B, C, -1))

        lst_pools = torch.cat(lst_pools, dim=2)
        lst_pools = lst_pools.permute(0, 2, 1)  # B, N, C

        gui_pools = torch.cat(gui_pools, dim=2)
        gui_pools = gui_pools.permute(0, 2, 1)  # B, N, C

        # Dynamic MLP
        weights = self.dynamic_mlp(lst_pools, gui_pools)  # B, N, C

        weights = torch.mean(weights, dim=1, keepdim=False).reshape(
            2, 2, self.kernel_size, self.kernel_size
        )  # in_chan=2, out_chan=2, kernel_size, kernel_size
        weights = nn.Parameter(data=weights, requires_grad=False)
        agg = F.conv2d(
            input=agg, weight=weights, stride=1, padding=self.kernel_size // 2, groups=1
        )
        sig = agg.sigmoid()
        attn1 = attn1 * sig[:, 0, :, :].unsqueeze(1)
        attn2 = attn2 * sig[:, 1, :, :].unsqueeze(1)
        out = self.conv(attn1 + attn2)

        return out * gui


# MoCoLSK Module
class MoCoLSKModule(nn.Module):
    """
    The MoCoLSK module.
    See paper: "GrokLST: Towards High-Resolution Benchmark and Toolkit for Land Surface Temperature Downscaling"
    Paper link: https://arxiv.org/abs/2409.19835v1
    Github: https://github.com/GrokCV/GrokLST
    """

    def __init__(
        self,
        lst_dim: int,
        gui_dim: int,
        scale: int,
        hidden: int = 32,
        num_layers: int = 1,
        mlp_type: str = "a",
        kernel_size: int = 3,
    ):
        """
        MoCoLSKModule.__init__
        Args:
            lst_dim (int): dimension of the LR LST data.
            gui_dim (int): dimension of the HR Guidance data.
            scale (int): up scale factor.
            hidden (int, optional): hidden dimension of the Dynamic MLP module. Defaults to 32.
            num_layers (int, optional): num_layers of the Dynamic MLP module. Defaults to 1.
            mlp_type (str, optional): mlp_type of the Dynamic MLP module. Defaults to "a".
            kernel_size (int, optional): kernel_size of dynamic weight generated by the Modality-Conditioned Weight Generation (MCWG) pathway. Defaults to 3.
        """
        super().__init__()
        self.lst_up = DenseProjection(
            lst_dim, gui_dim, scale, up=True, bottleneck=False
        )
        self.dlsk = MoCoLSK(
            gui_dim,
            gui_dim,
            hidden=hidden,
            num_layers=num_layers,
            mlp_type=mlp_type,
            kernel_size=kernel_size,
        )
        self.down = DenseProjection(
            2 * gui_dim, lst_dim + gui_dim, scale, up=False, bottleneck=False
        )

    def forward(self, depth, gui):
        lst_up = self.lst_up(depth)
        dlsk_feats = self.dlsk(lst_up, gui)
        feats = torch.cat([lst_up, dlsk_feats], dim=1)
        out = self.down(feats)

        return out


def default_conv(in_channels, out_channels, kernel_size, bias=True):
    return nn.Conv2d(
        in_channels, out_channels, kernel_size, padding=(kernel_size // 2), bias=bias
    )


def projection_conv(in_channels, out_channels, scale, up=True):
    kernel_size, stride, padding = {
        2: (6, 2, 2),
        4: (8, 4, 2),
        8: (12, 8, 2),
        16: (20, 16, 2),
    }[scale]
    if up:
        conv_f = nn.ConvTranspose2d
    else:
        conv_f = nn.Conv2d

    return conv_f(
        in_channels, out_channels, kernel_size, stride=stride, padding=padding
    )


class DenseProjection(nn.Module):
    def __init__(self, in_channels, nr, scale, up=True, bottleneck=True):
        super(DenseProjection, self).__init__()
        self.up = up
        if bottleneck:
            self.bottleneck = nn.Sequential(
                *[nn.Conv2d(in_channels, nr, 1), nn.PReLU(nr)]
            )
            inter_channels = nr
        else:
            self.bottleneck = None
            inter_channels = in_channels

        self.conv_1 = nn.Sequential(
            *[projection_conv(inter_channels, nr, scale, up), nn.PReLU(nr)]
        )
        self.conv_2 = nn.Sequential(
            *[
                projection_conv(nr, inter_channels, scale, not up),
                nn.PReLU(inter_channels),
            ]
        )
        self.conv_3 = nn.Sequential(
            *[projection_conv(inter_channels, nr, scale, up), nn.PReLU(nr)]
        )

    def forward(self, x):
        if self.bottleneck is not None:
            x = self.bottleneck(x)

        a_0 = self.conv_1(x)
        b_0 = self.conv_2(a_0)
        e = b_0.sub(x)
        a_1 = self.conv_3(e)

        out = a_0.add(a_1)
        return out


class ResBlock(nn.Module):
    def __init__(
        self,
        conv,
        n_feats,
        kernel_size,
        bias=True,
        bn=False,
        act=nn.ReLU(False),
        res_scale=1,
    ):
        super(ResBlock, self).__init__()
        m = []
        for i in range(2):
            m.append(conv(n_feats, n_feats, kernel_size, bias=bias))
            if bn:
                m.append(nn.BatchNorm2d(n_feats))
            if i == 0:
                m.append(act)

        self.body = nn.Sequential(*m)
        self.res_scale = res_scale

    def forward(self, x):
        res = self.body(x).mul(self.res_scale)
        res = res + x

        return res


# Residual Channel Attention Block (RCAB)
class RCAB(nn.Module):
    def __init__(
        self,
        conv,
        n_feat,
        kernel_size,
        reduction,
        bias=True,
        bn=False,
        act=nn.ReLU(False),
        res_scale=1,
    ):
        super(RCAB, self).__init__()
        modules_body = []
        for i in range(2):
            modules_body.append(conv(n_feat, n_feat, kernel_size, bias=bias))
            if bn:
                modules_body.append(nn.BatchNorm2d(n_feat))
            if i == 0:
                modules_body.append(act)
        modules_body.append(CALayer(n_feat, reduction))
        self.body = nn.Sequential(*modules_body)
        self.res_scale = res_scale

    def forward(self, x):
        res = self.body(x)
        # res = self.body(x).mul(self.res_scale)
        res = res + x
        return res


# Residual Group (RG)


class ResidualGroup(nn.Module):
    def __init__(self, conv, n_feat, kernel_size, reduction, n_resblocks):
        super(ResidualGroup, self).__init__()
        modules_body = []
        modules_body = [
            RCAB(
                conv,
                n_feat,
                kernel_size,
                reduction,
                bias=True,
                bn=False,
                act=nn.LeakyReLU(negative_slope=0.2, inplace=False),
                res_scale=1,
            )
            for _ in range(n_resblocks)
        ]
        modules_body.append(conv(n_feat, n_feat, kernel_size))
        self.body = nn.Sequential(*modules_body)

    def forward(self, x):
        res = self.body(x)
        res = res + x
        return res


# Channel Attention (CA) Layer
class CALayer(nn.Module):
    def __init__(self, channel, reduction=16):
        super(CALayer, self).__init__()
        # global average pooling: feature --> point
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        # feature channel downscale and upscale --> channel weight
        self.conv_du = nn.Sequential(
            nn.Conv2d(channel, channel // reduction, 1, padding=0, bias=True),
            nn.ReLU(inplace=False),
            nn.Conv2d(channel // reduction, channel, 1, padding=0, bias=True),
            nn.Sigmoid(),
        )

    def forward(self, x):
        y = self.avg_pool(x)
        y = self.conv_du(y)
        return x * y
